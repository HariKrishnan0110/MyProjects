import os
import asyncio
from dotenv import load_dotenv
from openai import AsyncAzureOpenAI

# Set to True to print the full response from OpenAI for each call
printFullResponse = False

async def main():
    try:
        # Load environment variables
        load_dotenv()
        azure_oai_endpoint = os.getenv("AZURE_OAI_ENDPOINT")
        azure_oai_key = os.getenv("AZURE_OAI_KEY")
        azure_oai_deployment = os.getenv("AZURE_OAI_DEPLOYMENT")

        # Initialize Azure OpenAI client
        client = AsyncAzureOpenAI(
            azure_endpoint=azure_oai_endpoint,
            api_key=azure_oai_key,
            api_version="2024-02-15-preview"
        )

        while True:
            print("------------------\nPausing the app to allow you to change the system prompt.\nPress enter to continue...")
            input()
            
            # Read system message
            try:
                with open("system.txt", encoding="utf8") as file:
                    system_text = file.read().strip()
            except FileNotFoundError:
                print("Error: system.txt file not found.")
                continue
            
            user_text = input("Enter user message, or 'quit' to exit: ")
            if user_text.lower() == 'quit' or system_text.lower() == 'quit':
                print('Exiting program...')
                break

            await call_openai_model(
                system_message=system_text,
                user_message=user_text,
                model=azure_oai_deployment,
                client=client
            )

    except Exception as ex:
        print(f"Error: {ex}")

async def call_openai_model(system_message, user_message, model, client):
    messages = [
        {"role": "system", "content": system_message},
        {"role": "user", "content": user_message},
    ]

    print("\nSending request to Azure OpenAI model...\n")

    try:
        response = await client.chat.completions.create(
            model=model,
            messages=messages,
            temperature=0.7,
            max_tokens=800
        )

        if printFullResponse:
            print(response)

        print("Response:\n" + response.choices[0].message.content + "\n")
    
    except Exception as ex:
        print(f"Error calling OpenAI model: {ex}")

if __name__ == '__main__':
    asyncio.run(main())
